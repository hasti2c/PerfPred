{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["DFAPA8Jfolo2"],"authorship_tag":"ABX9TyMYUEhvxmK+h6GgdwNx+NPw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"DFAPA8Jfolo2"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":346},"executionInfo":{"elapsed":2489,"status":"error","timestamp":1692102989449,"user":{"displayName":"Hasti Toossi","userId":"02154101839766812568"},"user_tz":-120},"id":"EZfeDaSwwb38","outputId":"25c9e382-e0fc-4158-d04d-b630d644ef6c"},"outputs":[{"output_type":"error","ename":"MessageError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-9a9a89271754>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    130\u001b[0m   )\n\u001b[1;32m    131\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive/')"]},{"cell_type":"code","source":["%cd \"/content/gdrive/MyDrive/PerfPred/Experiment/lang2vec\"\n","!python3 setup.py install"],"metadata":{"id":"lRtKeScdp8NO","executionInfo":{"status":"aborted","timestamp":1692102989450,"user_tz":-120,"elapsed":5,"user":{"displayName":"Hasti Toossi","userId":"02154101839766812568"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fUWBrJ8WuOXU","executionInfo":{"status":"aborted","timestamp":1692102989451,"user_tz":-120,"elapsed":6,"user":{"displayName":"Hasti Toossi","userId":"02154101839766812568"}}},"outputs":[],"source":["from google.colab import auth\n","from google.auth import default\n","import gspread\n","import lang2vec.lang2vec as l2v\n","import numpy as np\n","import pandas as pd\n","import scipy\n","from pprint import pprint\n","from scipy.spatial.distance import cosine\n","from sklearn.metrics.pairwise import cosine_distances"]},{"cell_type":"code","source":["auth.authenticate_user()\n","creds, _ = default()\n","gc = gspread.authorize(creds)"],"metadata":{"id":"_uiQ8XQZvb7j","executionInfo":{"status":"aborted","timestamp":1692102989451,"user_tz":-120,"elapsed":5,"user":{"displayName":"Hasti Toossi","userId":"02154101839766812568"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Features"],"metadata":{"id":"6Q9sanZWeUXr"}},{"cell_type":"code","source":["main_features = ['syntax_average', 'phonology_average', 'inventory_average',\n","               'syntax_knn', 'phonology_knn', 'inventory_knn', 'fam', 'geo']\n","extra_features = [\"+\".join(['syntax_average', 'phonology_average', 'inventory_average']),\n","                  \"+\".join(['syntax_knn', 'phonology_knn', 'inventory_knn']),\n","                  \"+\".join(['syntax_average', 'phonology_average', 'inventory_average', 'fam', 'geo']),\n","                  \"+\".join(['syntax_knn', 'phonology_knn', 'inventory_knn', 'fam', 'geo']),\n","                  \"+\".join(main_features)]\n","all_features = main_features + extra_features\n","N = len(all_features)"],"metadata":{"id":"Iswf1DGsecde"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def feature_vecs(feats, langs, sheet):\n","  data = l2v.get_features(langs, '+'.join(feats), header=True)\n","  df = pd.DataFrame(data)\n","  worksheet = gc.open('l2v self-calculated distances').get_worksheet(sheet)\n","  worksheet.update_title('+'.join(feats)[:100])\n","  worksheet.update([df.columns.values.tolist()] + df.values.tolist())\n","  return df"],"metadata":{"id":"IPSf_X4fegQS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dfs = []\n","langs = ['kan', 'guj', 'hin', 'sin', 'tam']\n","for i, feat in enumerate(all_features):\n","  dfs.append(feature_vecs([feat], [\"eng\"] + langs, i))"],"metadata":{"id":"omZkpUpAfE9V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def multiple_features(feats, lang, sheet):\n","  df = None\n","  for feat in feats:\n","    data = l2v.get_features(lang, feat, header=True)\n","    if df is None:\n","      df = pd.DataFrame(data, columns=[\"CODE\"])\n","    df[feat] = data[lang]\n","  worksheet = gc.open('l2v self-calculated distances').get_worksheet(sheet)\n","  worksheet.update_title(\"inv \" + lang)\n","  worksheet.update([df.columns.values.tolist()] + df.values.tolist())"],"metadata":{"id":"QjAR2nnyXYm2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["inv_features = ['inventory_ethnologue', 'inventory_phoible_aa',\n","                'inventory_phoible_gm', 'inventory_phoible_saphon',\n","                'inventory_phoible_spa', 'inventory_phoible_ph',\n","                'inventory_phoible_ra', 'inventory_phoible_upsid']\n","# N + 7\n","multiple_features(inv_features + [\"|\".join(inv_features)], \"hi\", N + 7)\n","# data = l2v.get_features(\"hi\", inv_features, header=True)\n","# df = pd.DataFrame(data)\n","# worksheet = gc.open('l2v self-calculated distances').get_worksheet(N + 7)\n","# worksheet.update_title(\"inventory\")\n","# worksheet.update([df.columns.values.tolist()] + df.values.tolist())"],"metadata":{"id":"jf9XCeYRWVuP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ret = l2v.get_features([\"eng\", \"hin\"], \"|\".join(inv_features))\n","eng, hin = ret[\"eng\"], ret[\"hin\"]\n","print(np.arccos(np.dot(eng / np.linalg.norm(eng), hin / np.linalg.norm(hin))))\n","print(scipy.spatial.distance.cosine(eng, hin))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gb-Tr7kdYyM4","executionInfo":{"status":"ok","timestamp":1687207366720,"user_tz":240,"elapsed":2753,"user":{"displayName":"Hasti Toossi","userId":"02154101839766812568"}},"outputId":"c3ca6e60-4fa8-40c4-9d27-1234bdfd23fa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.7357060106224771\n","0.25864287309665\n"]}]},{"cell_type":"markdown","source":["# Distances"],"metadata":{"id":"HWkWcjRMop2o"}},{"cell_type":"code","source":["def filter_df(df, langs):\n","  ret = df.copy()\n","  for lang in langs:\n","    ret = ret.loc[ret[lang] != '--']\n","  return ret"],"metadata":{"id":"9TUidg1trVsK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def distances(feats, langs, sheet1, sheet2, val_per_lang):\n","  cols = [\"feature\"] + langs\n","  dist_df = pd.DataFrame(columns=cols)\n","  num_df = pd.DataFrame(columns=cols)\n","  for i, feat in enumerate(feats):\n","    df = dfs[all_features.index(feat)]\n","    row = {\"feature\": feat}\n","    num_row = {\"feature\": feat}\n","    all_df = filter_df(df, [\"eng\"] + langs)\n","    for lang in langs:\n","      if val_per_lang:\n","        val_df = filter_df(df, [\"eng\", lang])\n","      else:\n","        val_df = all_df\n","      num_row[lang] = len(val_df)\n","      if len(val_df) == 0 or not np.any(val_df[\"eng\"]) or not np.any(val_df[lang]):\n","        row[lang] = '--'\n","        continue\n","      val = scipy.spatial.distance.cosine(val_df[\"eng\"], val_df[lang])\n","      row[lang] = np.round(val, decimals=4)\n","    dist_df.loc[len(dist_df.index)] = row\n","    num_df.loc[len(num_df.index)] = num_row\n","  worksheet1 = gc.open('l2v self-calculated distances').get_worksheet(sheet1)\n","  worksheet1.update([dist_df.columns.values.tolist()] + dist_df.values.tolist())\n","  worksheet2 = gc.open('l2v self-calculated distances').get_worksheet(sheet2)\n","  worksheet2.update([num_df.columns.values.tolist()] + num_df.values.tolist())\n","  return dist_df"],"metadata":{"id":"MZDmiQxTjjns"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["langs = ['kan', 'guj', 'hin', 'sin', 'tam']\n","dist_df = distances(all_features, langs, N, N + 1, True)"],"metadata":{"id":"FJ5MvPNIkhUv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["langs = ['kan', 'guj', 'hin', 'sin', 'tam']\n","dist_df = distances(all_features, langs, N + 2, N + 3, False)"],"metadata":{"id":"zqw4j3fxrR1l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["eng = dfs[5][\"eng\"]\n","kan = dfs[5][\"kan\"]\n","np.arccos(np.dot(eng / np.linalg.norm(eng), kan / np.linalg.norm(kan)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P5R3dMFB1w6f","executionInfo":{"status":"ok","timestamp":1687014235275,"user_tz":240,"elapsed":3,"user":{"displayName":"Hasti Toossi","userId":"02154101839766812568"}},"outputId":"454d4bab-a801-4698-cd9e-28126bc254ff"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.744244995555758"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["dfff = feature_vecs([\"|\".join(['inventory_ethnologue', 'inventory_phoible_aa',\n","                              'inventory_phoible_gm', 'inventory_phoible_saphon',\n","                              'inventory_phoible_spa', 'inventory_phoible_ph',\n","                              'inventory_phoible_ra', 'inventory_phoible_upsid'])],\n","                    [\"eng\"] + langs, N + 7)"],"metadata":{"id":"zeaMgZIK3IoK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["l2v.FEATURE_SETS"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bq--yyPi3MOt","executionInfo":{"status":"ok","timestamp":1687013890072,"user_tz":240,"elapsed":139,"user":{"displayName":"Hasti Toossi","userId":"02154101839766812568"}},"outputId":"34a96e6a-f7cc-4982-866f-950aadbe198b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['syntax_wals',\n"," 'phonology_wals',\n"," 'syntax_sswl',\n"," 'syntax_ethnologue',\n"," 'phonology_ethnologue',\n"," 'inventory_ethnologue',\n"," 'inventory_phoible_aa',\n"," 'inventory_phoible_gm',\n"," 'inventory_phoible_saphon',\n"," 'inventory_phoible_spa',\n"," 'inventory_phoible_ph',\n"," 'inventory_phoible_ra',\n"," 'inventory_phoible_upsid',\n"," 'syntax_knn',\n"," 'phonology_knn',\n"," 'inventory_knn',\n"," 'syntax_average',\n"," 'phonology_average',\n"," 'inventory_average',\n"," 'fam',\n"," 'id',\n"," 'geo',\n"," 'learned']"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["# Pre-calculated Distances"],"metadata":{"id":"Q5t-khGU7CTh"}},{"cell_type":"code","source":["def pre_calc_distances(feats, langs, sheet):\n","  cols=[\"distance\"] + langs\n","  dists = ['geographic', 'genetic', 'syntactic', 'phonological', 'inventory', 'featural']\n","  data = np.array(l2v.distance(dists, ['eng'] + langs))\n","  dist_df = pd.DataFrame(columns=cols)\n","  for i, dist in enumerate(dists):\n","    vals = data[i,0,1:]\n","    row = dict(zip(cols, [dist] + list(vals)))\n","    dist_df.loc[len(dist_df.index)] = row\n","  worksheet = gc.open('l2v self-calculated distances').get_worksheet(sheet)\n","  worksheet.update([dist_df.columns.values.tolist()] + dist_df.values.tolist())\n","  return dist_df"],"metadata":{"id":"VDF28IUd7FYb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["langs = ['kan', 'guj', 'hin', 'sin', 'tam']\n","dist_df = pre_calc_distances(all_features, langs, N + 5)"],"metadata":{"id":"yCCltkQr8IXy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Big Data Files"],"metadata":{"id":"luOtwLVRIPMg"}},{"cell_type":"code","source":["files = [\"FEATURAL\", \"GENETIC\", \"GEOGRAPHIC\", \"INVENTORY\", \"PHONOLOGICAL\", \"SYNTACTIC\"]\n","langs = ['kan', 'guj', 'hin', 'sin', 'tam']"],"metadata":{"id":"W74D2mDfK5Fm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for file in files:\n","  df = pd.read_csv(f\"data/distances/{file}.csv\", usecols=[\"G_CODE\", \"eng\"] + langs)\n","  df = df.loc[df[\"G_CODE\"].isin([\"eng\"] + langs)]\n","  df.to_csv(f\"data/truncated/{file}.csv\")"],"metadata":{"id":"EVoAvgbAIc2l"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Main Sheet"],"metadata":{"id":"U7VT94Ro1Fbz"}},{"cell_type":"code","source":["def distance_with_eng_main(feats, langs, sheet):\n","  cols = [\"feature\"] + [lang + \"-eng\" for lang in langs]\n","  dist_df = pd.DataFrame(columns=cols)\n","  for i, feat in enumerate(feats):\n","    df = dfs[all_features.index(feat)]\n","    row = {\"feature\": feat}\n","    for lang in langs:\n","      val = scipy.spatial.distance.cosine(df[\"eng\"], df[lang])\n","      row[lang + \"-eng\"] = np.round(val, decimals=4)\n","    dist_df.loc[len(dist_df.index)] = row\n","  worksheet = gc.open('Experiment 1 Data').get_worksheet(sheet)\n","  worksheet.update([dist_df.columns.values.tolist()] + dist_df.values.tolist())\n","  return dist_df"],"metadata":{"id":"8PssT2UP1FDB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["langs = ['kan', 'guj', 'hin', 'sin', 'tam']\n","select_features = ['syntax_knn', 'phonology_knn', 'inventory_knn', 'fam', 'geo',\n","                  \"+\".join(['syntax_knn', 'phonology_knn', 'inventory_knn'])]\n","dist_df = distance_with_eng_main(select_features, langs, 3)\n","# not this anymore, geo & gen taken from pre-calculated"],"metadata":{"id":"jxMkmexg1Wzg"},"execution_count":null,"outputs":[]}]}