{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["DFAPA8Jfolo2"],"authorship_tag":"ABX9TyNlGgFJ37iwGLfguHtD6cK7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"DFAPA8Jfolo2"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":789,"status":"ok","timestamp":1687206501537,"user":{"displayName":"Hasti Toossi","userId":"02154101839766812568"},"user_tz":240},"id":"EZfeDaSwwb38","outputId":"904d85f1-5772-4904-d8f6-e68b0985aecf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive/')"]},{"cell_type":"code","source":["%cd \"/content/gdrive/MyDrive/PerfPred/Experiment 1/lang2vec\"\n","!python3 setup.py install"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lRtKeScdp8NO","executionInfo":{"status":"ok","timestamp":1687206517357,"user_tz":240,"elapsed":3519,"user":{"displayName":"Hasti Toossi","userId":"02154101839766812568"}},"outputId":"77fbec67-7717-4b59-a107-2dcff42c5e64"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/.shortcut-targets-by-id/1vr6Z8seuUA0zoWaHuosCSZMv_H2Go5KR/PerfPred/Experiment 1/lang2vec\n","running install\n","/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n","!!\n","\n","        ********************************************************************************\n","        Please avoid running ``setup.py`` directly.\n","        Instead, use pypa/build, pypa/installer, pypa/build or\n","        other standards-based tools.\n","\n","        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n","        ********************************************************************************\n","\n","!!\n","  self.initialize_options()\n","/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: EasyInstallDeprecationWarning: easy_install command is deprecated.\n","!!\n","\n","        ********************************************************************************\n","        Please avoid running ``setup.py`` and ``easy_install``.\n","        Instead, use pypa/build, pypa/installer, pypa/build or\n","        other standards-based tools.\n","\n","        See https://github.com/pypa/setuptools/issues/917 for details.\n","        ********************************************************************************\n","\n","!!\n","  self.initialize_options()\n","running bdist_egg\n","running egg_info\n","writing lang2vec.egg-info/PKG-INFO\n","writing dependency_links to lang2vec.egg-info/dependency_links.txt\n","writing requirements to lang2vec.egg-info/requires.txt\n","writing top-level names to lang2vec.egg-info/top_level.txt\n","reading manifest file 'lang2vec.egg-info/SOURCES.txt'\n","adding license file 'LICENSE.txt'\n","writing manifest file 'lang2vec.egg-info/SOURCES.txt'\n","installing library code to build/bdist.linux-x86_64/egg\n","running install_lib\n","running build_py\n","creating build/bdist.linux-x86_64/egg\n","creating build/bdist.linux-x86_64/egg/lang2vec\n","copying build/lib/lang2vec/lang2vec.py -> build/bdist.linux-x86_64/egg/lang2vec\n","copying build/lib/lang2vec/__init__.py -> build/bdist.linux-x86_64/egg/lang2vec\n","creating build/bdist.linux-x86_64/egg/lang2vec/data\n","copying build/lib/lang2vec/data/learned.npy -> build/bdist.linux-x86_64/egg/lang2vec/data\n","copying build/lib/lang2vec/data/features.npz -> build/bdist.linux-x86_64/egg/lang2vec/data\n","copying build/lib/lang2vec/data/feature_averages.npz -> build/bdist.linux-x86_64/egg/lang2vec/data\n","copying build/lib/lang2vec/data/letter_codes.json -> build/bdist.linux-x86_64/egg/lang2vec/data\n","copying build/lib/lang2vec/data/feature_predictions.npz -> build/bdist.linux-x86_64/egg/lang2vec/data\n","copying build/lib/lang2vec/data/distances_languages.txt -> build/bdist.linux-x86_64/egg/lang2vec/data\n","copying build/lib/lang2vec/data/family_features.npz -> build/bdist.linux-x86_64/egg/lang2vec/data\n","copying build/lib/lang2vec/data/geocoord_features.npz -> build/bdist.linux-x86_64/egg/lang2vec/data\n","copying build/lib/lang2vec/data/distances2.zip -> build/bdist.linux-x86_64/egg/lang2vec/data\n","byte-compiling build/bdist.linux-x86_64/egg/lang2vec/lang2vec.py to lang2vec.cpython-310.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/lang2vec/__init__.py to __init__.cpython-310.pyc\n","creating build/bdist.linux-x86_64/egg/EGG-INFO\n","installing scripts to build/bdist.linux-x86_64/egg/EGG-INFO/scripts\n","running install_scripts\n","running build_scripts\n","changing mode of build/scripts-3.10/lang2vec.py from 700 to 755\n","creating build/bdist.linux-x86_64/egg/EGG-INFO/scripts\n","copying build/scripts-3.10/lang2vec.py -> build/bdist.linux-x86_64/egg/EGG-INFO/scripts\n","changing mode of build/bdist.linux-x86_64/egg/EGG-INFO/scripts/lang2vec.py to 755\n","copying lang2vec.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying lang2vec.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying lang2vec.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying lang2vec.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying lang2vec.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying lang2vec.egg-info/zip-safe -> build/bdist.linux-x86_64/egg/EGG-INFO\n","creating 'dist/lang2vec-1.1.6-py3.10.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n","removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n","Processing lang2vec-1.1.6-py3.10.egg\n","Removing /usr/local/lib/python3.10/dist-packages/lang2vec-1.1.6-py3.10.egg\n","Copying lang2vec-1.1.6-py3.10.egg to /usr/local/lib/python3.10/dist-packages\n","lang2vec 1.1.6 is already the active version in easy-install.pth\n","Installing lang2vec.py script to /usr/local/bin\n","\n","Installed /usr/local/lib/python3.10/dist-packages/lang2vec-1.1.6-py3.10.egg\n","Processing dependencies for lang2vec==1.1.6\n","Searching for scipy==1.10.1\n","Best match: scipy 1.10.1\n","Adding scipy 1.10.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for setuptools==67.7.2\n","Best match: setuptools 67.7.2\n","Adding setuptools 67.7.2 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for numpy==1.22.4\n","Best match: numpy 1.22.4\n","Adding numpy 1.22.4 to easy-install.pth file\n","Installing f2py script to /usr/local/bin\n","Installing f2py3 script to /usr/local/bin\n","Installing f2py3.10 script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Finished processing dependencies for lang2vec==1.1.6\n"]}]},{"cell_type":"code","execution_count":5,"metadata":{"id":"fUWBrJ8WuOXU","executionInfo":{"status":"ok","timestamp":1687206525551,"user_tz":240,"elapsed":8196,"user":{"displayName":"Hasti Toossi","userId":"02154101839766812568"}}},"outputs":[],"source":["from google.colab import auth\n","from google.auth import default\n","import gspread\n","import lang2vec.lang2vec as l2v\n","import numpy as np\n","import pandas as pd\n","import scipy\n","from pprint import pprint\n","from scipy.spatial.distance import cosine\n","from sklearn.metrics.pairwise import cosine_distances"]},{"cell_type":"code","source":["auth.authenticate_user()\n","creds, _ = default()\n","gc = gspread.authorize(creds)"],"metadata":{"id":"_uiQ8XQZvb7j","executionInfo":{"status":"ok","timestamp":1687206528745,"user_tz":240,"elapsed":289,"user":{"displayName":"Hasti Toossi","userId":"02154101839766812568"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["# Features"],"metadata":{"id":"6Q9sanZWeUXr"}},{"cell_type":"code","source":["main_features = ['syntax_average', 'phonology_average', 'inventory_average',\n","               'syntax_knn', 'phonology_knn', 'inventory_knn', 'fam', 'geo']\n","extra_features = [\"+\".join(['syntax_average', 'phonology_average', 'inventory_average']),\n","                  \"+\".join(['syntax_knn', 'phonology_knn', 'inventory_knn']),\n","                  \"+\".join(['syntax_average', 'phonology_average', 'inventory_average', 'fam', 'geo']),\n","                  \"+\".join(['syntax_knn', 'phonology_knn', 'inventory_knn', 'fam', 'geo']),\n","                  \"+\".join(main_features)]\n","all_features = main_features + extra_features\n","N = len(all_features)"],"metadata":{"id":"Iswf1DGsecde","executionInfo":{"status":"ok","timestamp":1687206533224,"user_tz":240,"elapsed":128,"user":{"displayName":"Hasti Toossi","userId":"02154101839766812568"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def feature_vecs(feats, langs, sheet):\n","  data = l2v.get_features(langs, '+'.join(feats), header=True)\n","  df = pd.DataFrame(data)\n","  worksheet = gc.open('l2v self-calculated distances').get_worksheet(sheet)\n","  worksheet.update_title('+'.join(feats)[:100])\n","  worksheet.update([df.columns.values.tolist()] + df.values.tolist())\n","  return df"],"metadata":{"id":"IPSf_X4fegQS","executionInfo":{"status":"ok","timestamp":1687206536887,"user_tz":240,"elapsed":121,"user":{"displayName":"Hasti Toossi","userId":"02154101839766812568"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["dfs = []\n","langs = ['kan', 'guj', 'hin', 'sin', 'tam']\n","for i, feat in enumerate(all_features):\n","  dfs.append(feature_vecs([feat], [\"eng\"] + langs, i))"],"metadata":{"id":"omZkpUpAfE9V","executionInfo":{"status":"aborted","timestamp":1687206511865,"user_tz":240,"elapsed":3,"user":{"displayName":"Hasti Toossi","userId":"02154101839766812568"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def multiple_features(feats, lang, sheet):\n","  df = None\n","  for feat in feats:\n","    data = l2v.get_features(lang, feat, header=True)\n","    if df is None:\n","      df = pd.DataFrame(data, columns=[\"CODE\"])\n","    df[feat] = data[lang]\n","  worksheet = gc.open('l2v self-calculated distances').get_worksheet(sheet)\n","  worksheet.update_title(\"inv \" + lang)\n","  worksheet.update([df.columns.values.tolist()] + df.values.tolist())"],"metadata":{"id":"QjAR2nnyXYm2","executionInfo":{"status":"ok","timestamp":1687207142773,"user_tz":240,"elapsed":3,"user":{"displayName":"Hasti Toossi","userId":"02154101839766812568"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["inv_features = ['inventory_ethnologue', 'inventory_phoible_aa',\n","                'inventory_phoible_gm', 'inventory_phoible_saphon',\n","                'inventory_phoible_spa', 'inventory_phoible_ph',\n","                'inventory_phoible_ra', 'inventory_phoible_upsid']\n","# N + 7\n","multiple_features(inv_features + [\"|\".join(inv_features)], \"hi\", N + 7)\n","# data = l2v.get_features(\"hi\", inv_features, header=True)\n","# df = pd.DataFrame(data)\n","# worksheet = gc.open('l2v self-calculated distances').get_worksheet(N + 7)\n","# worksheet.update_title(\"inventory\")\n","# worksheet.update([df.columns.values.tolist()] + df.values.tolist())"],"metadata":{"id":"jf9XCeYRWVuP","executionInfo":{"status":"ok","timestamp":1687207180671,"user_tz":240,"elapsed":6050,"user":{"displayName":"Hasti Toossi","userId":"02154101839766812568"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["ret = l2v.get_features([\"eng\", \"hin\"], \"|\".join(inv_features))\n","eng, hin = ret[\"eng\"], ret[\"hin\"]\n","print(np.arccos(np.dot(eng / np.linalg.norm(eng), hin / np.linalg.norm(hin))))\n","print(scipy.spatial.distance.cosine(eng, hin))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gb-Tr7kdYyM4","executionInfo":{"status":"ok","timestamp":1687207366720,"user_tz":240,"elapsed":2753,"user":{"displayName":"Hasti Toossi","userId":"02154101839766812568"}},"outputId":"c3ca6e60-4fa8-40c4-9d27-1234bdfd23fa"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["0.7357060106224771\n","0.25864287309665\n"]}]},{"cell_type":"markdown","source":["# Distances"],"metadata":{"id":"HWkWcjRMop2o"}},{"cell_type":"code","source":["def filter_df(df, langs):\n","  ret = df.copy()\n","  for lang in langs:\n","    ret = ret.loc[ret[lang] != '--']\n","  return ret"],"metadata":{"id":"9TUidg1trVsK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def distances(feats, langs, sheet1, sheet2, val_per_lang):\n","  cols = [\"feature\"] + langs\n","  dist_df = pd.DataFrame(columns=cols)\n","  num_df = pd.DataFrame(columns=cols)\n","  for i, feat in enumerate(feats):\n","    df = dfs[all_features.index(feat)]\n","    row = {\"feature\": feat}\n","    num_row = {\"feature\": feat}\n","    all_df = filter_df(df, [\"eng\"] + langs)\n","    for lang in langs:\n","      if val_per_lang:\n","        val_df = filter_df(df, [\"eng\", lang])\n","      else:\n","        val_df = all_df\n","      num_row[lang] = len(val_df)\n","      if len(val_df) == 0 or not np.any(val_df[\"eng\"]) or not np.any(val_df[lang]):\n","        row[lang] = '--'\n","        continue\n","      val = scipy.spatial.distance.cosine(val_df[\"eng\"], val_df[lang])\n","      row[lang] = np.round(val, decimals=4)\n","    dist_df.loc[len(dist_df.index)] = row\n","    num_df.loc[len(num_df.index)] = num_row\n","  worksheet1 = gc.open('l2v self-calculated distances').get_worksheet(sheet1)\n","  worksheet1.update([dist_df.columns.values.tolist()] + dist_df.values.tolist())\n","  worksheet2 = gc.open('l2v self-calculated distances').get_worksheet(sheet2)\n","  worksheet2.update([num_df.columns.values.tolist()] + num_df.values.tolist())\n","  return dist_df"],"metadata":{"id":"MZDmiQxTjjns"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["langs = ['kan', 'guj', 'hin', 'sin', 'tam']\n","dist_df = distances(all_features, langs, N, N + 1, True)"],"metadata":{"id":"FJ5MvPNIkhUv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["langs = ['kan', 'guj', 'hin', 'sin', 'tam']\n","dist_df = distances(all_features, langs, N + 2, N + 3, False)"],"metadata":{"id":"zqw4j3fxrR1l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["eng = dfs[5][\"eng\"]\n","kan = dfs[5][\"kan\"]\n","np.arccos(np.dot(eng / np.linalg.norm(eng), kan / np.linalg.norm(kan)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P5R3dMFB1w6f","executionInfo":{"status":"ok","timestamp":1687014235275,"user_tz":240,"elapsed":3,"user":{"displayName":"Hasti Toossi","userId":"02154101839766812568"}},"outputId":"454d4bab-a801-4698-cd9e-28126bc254ff"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.744244995555758"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["dfff = feature_vecs([\"|\".join(['inventory_ethnologue', 'inventory_phoible_aa',\n","                              'inventory_phoible_gm', 'inventory_phoible_saphon',\n","                              'inventory_phoible_spa', 'inventory_phoible_ph',\n","                              'inventory_phoible_ra', 'inventory_phoible_upsid'])],\n","                    [\"eng\"] + langs, N + 7)"],"metadata":{"id":"zeaMgZIK3IoK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["l2v.FEATURE_SETS"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bq--yyPi3MOt","executionInfo":{"status":"ok","timestamp":1687013890072,"user_tz":240,"elapsed":139,"user":{"displayName":"Hasti Toossi","userId":"02154101839766812568"}},"outputId":"34a96e6a-f7cc-4982-866f-950aadbe198b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['syntax_wals',\n"," 'phonology_wals',\n"," 'syntax_sswl',\n"," 'syntax_ethnologue',\n"," 'phonology_ethnologue',\n"," 'inventory_ethnologue',\n"," 'inventory_phoible_aa',\n"," 'inventory_phoible_gm',\n"," 'inventory_phoible_saphon',\n"," 'inventory_phoible_spa',\n"," 'inventory_phoible_ph',\n"," 'inventory_phoible_ra',\n"," 'inventory_phoible_upsid',\n"," 'syntax_knn',\n"," 'phonology_knn',\n"," 'inventory_knn',\n"," 'syntax_average',\n"," 'phonology_average',\n"," 'inventory_average',\n"," 'fam',\n"," 'id',\n"," 'geo',\n"," 'learned']"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["# Pre-calculated Distances"],"metadata":{"id":"Q5t-khGU7CTh"}},{"cell_type":"code","source":["def pre_calc_distances(feats, langs, sheet):\n","  cols=[\"distance\"] + langs\n","  dists = ['geographic', 'genetic', 'syntactic', 'phonological', 'inventory', 'featural']\n","  data = np.array(l2v.distance(dists, ['eng'] + langs))\n","  dist_df = pd.DataFrame(columns=cols)\n","  for i, dist in enumerate(dists):\n","    vals = data[i,0,1:]\n","    row = dict(zip(cols, [dist] + list(vals)))\n","    dist_df.loc[len(dist_df.index)] = row\n","  worksheet = gc.open('l2v self-calculated distances').get_worksheet(sheet)\n","  worksheet.update([dist_df.columns.values.tolist()] + dist_df.values.tolist())\n","  return dist_df"],"metadata":{"id":"VDF28IUd7FYb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["langs = ['kan', 'guj', 'hin', 'sin', 'tam']\n","dist_df = pre_calc_distances(all_features, langs, N + 5)"],"metadata":{"id":"yCCltkQr8IXy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Big Data Files"],"metadata":{"id":"luOtwLVRIPMg"}},{"cell_type":"code","source":["files = [\"FEATURAL\", \"GENETIC\", \"GEOGRAPHIC\", \"INVENTORY\", \"PHONOLOGICAL\", \"SYNTACTIC\"]\n","langs = ['kan', 'guj', 'hin', 'sin', 'tam']"],"metadata":{"id":"W74D2mDfK5Fm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for file in files:\n","  df = pd.read_csv(f\"data/distances/{file}.csv\", usecols=[\"G_CODE\", \"eng\"] + langs)\n","  df = df.loc[df[\"G_CODE\"].isin([\"eng\"] + langs)]\n","  df.to_csv(f\"data/truncated/{file}.csv\")"],"metadata":{"id":"EVoAvgbAIc2l"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Main Sheet"],"metadata":{"id":"U7VT94Ro1Fbz"}},{"cell_type":"code","source":["def distance_with_eng_main(feats, langs, sheet):\n","  cols = [\"feature\"] + [lang + \"-eng\" for lang in langs]\n","  dist_df = pd.DataFrame(columns=cols)\n","  for i, feat in enumerate(feats):\n","    df = dfs[all_features.index(feat)]\n","    row = {\"feature\": feat}\n","    for lang in langs:\n","      val = scipy.spatial.distance.cosine(df[\"eng\"], df[lang])\n","      row[lang + \"-eng\"] = np.round(val, decimals=4)\n","    dist_df.loc[len(dist_df.index)] = row\n","  worksheet = gc.open('Experiment 1 Data').get_worksheet(sheet)\n","  worksheet.update([dist_df.columns.values.tolist()] + dist_df.values.tolist())\n","  return dist_df"],"metadata":{"id":"8PssT2UP1FDB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["langs = ['kan', 'guj', 'hin', 'sin', 'tam']\n","select_features = ['syntax_knn', 'phonology_knn', 'inventory_knn', 'fam', 'geo',\n","                  \"+\".join(['syntax_knn', 'phonology_knn', 'inventory_knn'])]\n","dist_df = distance_with_eng_main(select_features, langs, 3)\n","# not this anymore, geo & gen taken from pre-calculated"],"metadata":{"id":"jxMkmexg1Wzg"},"execution_count":null,"outputs":[]}]}